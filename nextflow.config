/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    nf-core/plantpathsurveil Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/


// Global default params, used in configs
params {

    // Input options
    sample_data                = null
    reference_data             = null
    bakta_db                   = null
    temp_dir                   = null
    data_dir                   = 'path_surveil_data'
    download_bakta_db          = false
    max_depth                  = 100
    n_ref_strains              = 30
    n_ref_species              = 20
    n_ref_genera               = 10
    n_ref_closest              = 3
    n_ref_context              = 5
    ref_min_ani                = 0.9
    phylo_min_genes            = 10
    phylo_max_genes            = 100
    bakta_db_type              = 'light'
    cache_type                 = 'true'

    // MultiQC options
    multiqc_config             = null
    multiqc_title              = null
    multiqc_logo               = null
    max_multiqc_email_size     = '25.MB'
    multiqc_methods_description = null

    // Boilerplate options
    out_dir                    = null
    trace_dir                  = "${params.out_dir}/pipeline_info"
    publish_dir_mode           = 'copy'
    copymode                   = 'medium'
    email                      = null
    email_on_fail              = null
    plaintext_email            = false
    monochrome_logs            = false
    hook_url                   = null
    help                       = false
    validate_params            = true
    show_hidden_params         = false
    schema_ignore_params       = 'genomes'
    enable_conda               = false
    hpc_queue                  = null

    // Config options
    custom_config_version      = 'master'
    custom_config_base         = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
    config_profile_description = null
    config_profile_contact     = null
    config_profile_url         = null
    config_profile_name        = null

    // Max resource options for individual jobs
    // Defaults only, expecting to be overwritten
    max_memory                 = '64.GB'
    max_cpus                   = 16
    max_time                   = '240.h'
    // Max total options for all jobs combined
    max_total_memory           = null
    max_total_cpus             = null
    max_total_jobs             = null
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load nf-core custom profiles from different Institutions
try {
    includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
    System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

// Load nf-core/plantpathsurveil custom profiles from different institutions.
// Warning: Uncomment only if a pipeline-specific instititutional config already exists on nf-core/configs!
// try {
//   includeConfig "${params.custom_config_base}/pipeline/plantpathsurveil.config"
// } catch (Exception e) {
//   System.err.println("WARNING: Could not load nf-core/config/plantpathsurveil profiles: ${params.custom_config_base}/pipeline/plantpathsurveil.config")
// }

executor.cpus = params.max_total_cpus
executor.memory = params.max_total_memory
executor.queueSize = params.max_total_jobs

profiles {
    debug { process.beforeScript = 'echo $HOSTNAME' }
    conda {
        conda.enabled          = true
        params.enable_conda    = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    mamba {
        conda.enabled          = true
        params.enable_conda    = true
        conda.useMamba         = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    docker {
        docker.registry        = 'quay.io'
        docker.enabled         = true
        docker.runOptions      = '-u $(id -u):$(id -g)' // replaces the depreciated 'docker.userEmulation' option
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    podman {
        podman.enabled         = true
        docker.enabled         = false
        singularity.enabled    = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    shifter {
        shifter.enabled        = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        charliecloud.enabled   = false
    }
    charliecloud {
        charliecloud.enabled   = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
    }
    gitpod {
        executor.name          = 'local'
        executor.cpus          = 16
        executor.memory        = 60.GB
    }
    slurm {
        executor.name = 'slurm' // Use SLURM for job scheduling
        process.queue = params.hpc_queue // SLURM partition
        executor.clusterOptions = '--qos=normal' // Additional SLURM options
        executor.perCpuMemAllocation = false // Enable per-CPU memory allocation if required by the cluster
    }
    xanthomonas                 { includeConfig 'conf/xanthomonas.config' }
    xanthomonas_small           { includeConfig 'conf/xanthomonas_small.config' }
    ramorum_small               { includeConfig 'conf/ramorum_small.config' }
    mixed                       { includeConfig 'conf/mixed.config' }
    mixed_bacteria              { includeConfig 'conf/mixed_bacteria.config' }
    mycobacteroides             { includeConfig 'conf/mycobacteroides.config' }
    mycobacteroides_small       { includeConfig 'conf/mycobacteroides_small.config' }
    high_complexity_kpneumoniae { includeConfig 'conf/high_complexity_kpneumoniae.config' }
    wagner_2023                 { includeConfig 'conf/wagner_2023.config' }
    wagner_2023_small           { includeConfig 'conf/wagner_2023_small.config' }
    chaos                       { includeConfig 'conf/chaos.config' }
    aps_workshop                { includeConfig 'conf/aps_workshop.config' }
    test                        { includeConfig 'conf/test.config' }
    test_full                   { includeConfig 'conf/test_full.config' }
    ppluvialis                  { includeConfig 'conf/ppluvialis.config' }
    complex_dataset_small       { includeConfig 'conf/complex_dataset_small.config' } 
    cqls                        { includeConfig 'conf/cqls.config' }
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.trace_dir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.trace_dir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.trace_dir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.trace_dir}/pipeline_dag_${trace_timestamp}.html"
}

manifest {
    name            = 'nf-core/plantpathsurveil'
    author          = 'Zachary S.L. Foster, Martha Sudermann, Nicholas C. Cauldron, Fernanda I. Bocardo, Hung Phan, Jeﬀ H. Chang, Niklaus J. Grünwald'
    homePage        = 'https://github.com/nf-core/plantpathsurveil'
    description     = 'Surveillance of plant pathogens using high-throughput sequencing'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=21.10.3'
    version         = '1.0dev'
    doi             = ''
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

def check_prio(copymode_level, copy_priority) {
    if (copymode_level == 'high') {
        return 'copy'
    } else if (copymode_level == 'medium' && copy_priority != 'low') {
        return 'copy'
    } else {
        return 'symlink'
    }
}
