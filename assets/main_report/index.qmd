---
title: Pathogen Surveillance Report
params:
    group: "xan_test"
    refs: "22_331_assembly"
    samp_data: "_test_data/metadata_medium.csv"
    ref_data: "_test_data/merged_assembly_stats.tsv"
    sendsketch: "_test_data/sendsketch"
    variant_data: "_test_data/variant_data"
    ani_matrix: "_test_data/xan_test_comp.csv"
    core_phylo: "_test_data/xan_test.treefile"
    multiqc: "_test_data/multiqc"
    quast: "_test_data/quast"
    versions: "_test_data/software_versions.yml"
execute:
  echo: false
---

```{r knitr_settings}
knitr::opts_chunk$set(echo = FALSE, fig.width = 10, warning = FALSE)
```

```{r load_libraries, warning=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
library(readr)
library(knitr)
library(readr)
library(purrr)
library(yaml)
library(phylocanvas)
library(ape)
library(magrittr)
library(pheatmap)
library(tidyverse)
library(palmerpenguins)
library(ade4)
library(adegenet)
library(poppr)
library(ggtree)
library(igraph)
library(visNetwork)
library(phangorn)
library(ggplot2)
library(ggnewscale)
library(kableExtra)
```

```{r parse_inputs}
# If being run manually (no params), then get default params from yaml header
if (! exists("params")) {
    header <- rmarkdown::yaml_front_matter('index.qmd')
    params <- as.list(header$params)
}

# Parse metadata
group <- params$group
refs <- strsplit(params$refs, ';', fixed = TRUE)[[1]]
all_samp_data <- read_csv(params$samp_data, show_col_types = FALSE)
group_data <- strsplit(all_samp_data$report_group, split = ";")
all_groups <- unique(unlist(group_data))
samp_data <- all_samp_data[map_lgl(group_data, function(x) group %in% x), ]
ref_data <- read_tsv(params$ref_data, col_types = 'dcccccccccccccccddc')

# Parse sendsketch data
sketch_data <- map_dfr(list.files(params$sendsketch), function(path) {
    data <- read_tsv(file.path(params$sendsketch, path), skip = 2,
                     show_col_types = FALSE)
    id <- sub(path, pattern = '\\.txt$', replacement = '')
    return(bind_cols(sample_id = rep(id, nrow(data)), data))
})

# Parse variant data
snp_tree_paths <- list.files(params$variant_data, pattern = "\\.treefile$", full.names = TRUE)
vcf_paths <- list.files(params$variant_data, pattern = "\\.vcf\\.gz$", full.names = TRUE)
snp_align_paths <- list.files(params$variant_data, pattern = "\\.fasta$", full.names = TRUE)

# Parse ANI matrix
ani_matrix <- read.csv(params$ani_matrix, check.names = FALSE)
rownames(ani_matrix) <- colnames(ani_matrix)

# Parse core gene phylogeny
core_phylo_path = params$core_phylo

# Parse quality control data
multiqc_report_path <- file.path(params$multiqc, 'multiqc_report.html')
quast_ref_names <- list.files(params$quast)
quast_report_paths <- file.path(quast_ref_names, 'report.html')

# Parse version data
raw_version_data <- unlist(read_yaml(params$versions))
version_data <- tibble(
    module = map_chr(strsplit(names(raw_version_data), split = '.', fixed = TRUE), `[`, 1),
    program = map_chr(strsplit(names(raw_version_data), split = '.', fixed = TRUE), `[`, 2),
    version = unname(raw_version_data)
)
```

# Run Summary

This report is produced by the **`nf-core/pathogensurveillance` pipeline** version **{{< var version >}}**.

| <!-- --> | <!-- --> | 
|-----|-----|
| **Report group:**   | `r group` |
| **Sample count:**   | `r nrow(samp_data)` |
| **Last updated**    | `r format(Sys.time(), '%B %d , %Y')` |

## Status

Perhaps a table with a list of majors steps and a icon next to each for done/queued/failed.

## Input data

```{r}
samp_data %>%
    select(
        `Sample ID`=sample,
        `Forward Reads`=fastq_1,
        `Reverse Reads`=fastq_2,
        `Reference ID`=reference_id,
        `Reference`=reference) %>%
    DT::datatable()
```

## Input settings

Add settings used to run Nextflow and the pipeline parameters.



    

# Identification


## Most similar organisms

The following table provides putative classifications of the samples based on a kmer classification analysis. It is important to note that these are preliminary identifications. The table incorporates several key metrics: Weighted Kmer IDentity (WKID), Average Nucleotide Identity (ANI), and Completeness. These metrics provide insights into the genomic similarity and representational completeness between the query and reference genomes.

```{r sketchtable,fig.width=5}
# Load additional packages for aesthetic formatting
#install.packages("kableExtra")

# Convert percentage fields from character to numeric
sketch_data$WKID <- as.numeric(gsub("%", "", sketch_data$WKID))
sketch_data$ANI <- as.numeric(gsub("%", "", sketch_data$ANI))
sketch_data$Complt <- as.numeric(gsub("%", "", sketch_data$Complt))

# Sort and filter data
final_table <- sketch_data %>%
  arrange(desc(sample_id), desc(WKID), desc(ANI), desc(Complt)) %>%  # Sort by sample_id, WKID, ANI, and Complt in descending order
  group_by(sample_id) %>%  # Group by sample_id
  slice_head(n = 1) %>%  # Take the first entry per group
  ungroup() %>%  # Remove grouping
  select(sample_id, WKID, ANI, Complt, taxName) %>%  # Select required columns
  rename(Sample = sample_id, 
         `WKID (%)` = WKID,
         `ANI (%)` = ANI,
         `Completeness (%)` = Complt,
         `Top Hit` = taxName)  # Rename columns

# Define a function called 'bordered_bar' that takes two arguments: 'value' and 'color'
bordered_bar <- function(value, color) {
  sprintf('<div style="border: 1px solid gray; width: 100%%; border-radius: 12px;">
            <div style="width: %s%%; background-color: %s; border-radius: 12px; text-align: center;">%s</div>
           </div>', 
          value, color, value)
}

# Apply the bordered_bar function to the relevant columns
final_table$`WKID (%)` <- sapply(final_table$`WKID (%)`, function(x) bordered_bar(x, 'lightblue'))
final_table$`ANI (%)` <- sapply(final_table$`ANI (%)`, function(x) bordered_bar(x, 'lightgreen'))
final_table$`Completeness (%)` <- sapply(final_table$`Completeness (%)`, function(x) bordered_bar(x, 'lightpink'))

# Render the table using DT for HTML output, which will make it interactive
DT::datatable(final_table, 
          options = list(
            pageLength = 10,  # Show 10 entries per page
            autoWidth = TRUE,  # Automatically adjust column width
            columnDefs = list(
              list(width = '150px', targets = c(1, 2, 3))
            ),
            searchHighlight = TRUE  # Highlight search results
          ),
          rownames = FALSE,  # Hide row numbers
          escape = FALSE  # Necessary if your table has HTML content, like the bordered bars
)



# Render the table using kable and kableExtra for HTML output
#final_table %>%
#  knitr::kable("html", escape = F, align = c('l', 'c', 'c', 'c', 'l')) %>%
#  kable_styling(bootstrap_options = "striped", full_width = F) %>%
#  column_spec(2, extra_css = "width: 150px;") %>%
#  column_spec(3, extra_css = "width: 150px;") %>%
#  column_spec(4, extra_css = "width: 150px;") %>%
#  column_spec(5, extra_css = "width: 350px;") %>%
#  column_spec(1:5, extra_css = "font-size: 14px;")


```


::: {.callout-note}
WKID represents the Weighted Kmer IDentity, adjusted for genome size differences. ANI, or Average Nucleotide Identity, is derived from WKID and kmer length. Completeness indicates the percentage of the reference genome represented in the query, and is derived from WKID and KID.
:::

## Phylogenetic context

::: {.panel-tabset}

### Core genome phylogeny

```{r id_core_phylo}
convert_id <- function(ids) {
    gsub(ids, pattern = "[.-]", replacement = "_")
}

core_tree <- ape::read.tree(core_phylo_path)

# Identify which tips are samples and references
sample_ids <- core_tree$tip.label[core_tree$tip.label %in% convert_id(samp_data$sample)]

# Root tree 
colnames(ani_matrix) <- convert_id(colnames(ani_matrix))
rownames(ani_matrix) <- colnames(ani_matrix)
group_ani <- ani_matrix[rownames(ani_matrix) %in% core_tree$tip.label, colnames(ani_matrix) %in% core_tree$tip.label]
core_tree <- root(core_tree, names(which.min(colMeans(group_ani[sample_ids, ]))))

# Set tip labels to taxon names for reference sequences
# TODO: need a more reliable way to get IDs
name_key <- c(
  ref_data$Organism, 
  samp_data$sample
)
names(name_key) <- c(
  convert_id(ref_data$LastMajorReleaseAccession),
  convert_id(samp_data$sample)
)
core_tree$tip.label <- name_key[core_tree$tip.label]

# Plot tree
phycanv <- phylocanvas(core_tree, treetype = "rectangular", alignlabels = T, showscalebar = T, width = "100%")
for (x in name_key[sample_ids]) {
  phycanv <- style_node(phycanv, x, labelcolor = "green", labeltextsize = 30)
}
    
phycanv
```


### ANI heatmap and dendrogram

*Martha-Not sure if this is useful, but one idea. The interactive version wasn't that useful-but maybe other options*

```{r ANI dendrogram, fig.height = 8, fig.width=8}
p1 <- pheatmap(ani_matrix, show_rownames = T, labels_row = colnames(ani_matrix))
p1
```


:::





# Diversity

*Things to address:*

1.  There are lots of NAs in metadata. I ran into issues when trying run poppr and I was trying to select a specific column to color nodes. As a quick workaround, changed these to 'unknown', but what is a better solution?
2.  The assembly prefix in sample names present in SNP aln output and treefile need to be addressed. In initial tool testing stage, I (Martha) have provided some quick workarounds, but this should be addressed at a larger level.

```{r div_parse_inputs}
#ref_meta <- read.csv(params$ref_data, sep = '\t')
#ref_meta$modified_id <- gsub(ref_meta$LastMajorReleaseAccession, pattern = ".", replacement = "_", fixed = TRUE)
samp_meta <- read.csv(params$samp_data, sep = ',')
samp_meta$modified_id <- paste0(gsub(samp_meta$sample, pattern = "-", replacement = "_", fixed = TRUE), "_T1")
#core_tree <- ape::read.tree(core_phylo_path)
#not sure this is the intended way to create snp_tree path, but just added this temporarily so everything could render
snp_tree_paths <-file.path(params$variant_data, "xan_test_22_331_assembly.treefile")
snp_align_paths <-file.path(params$variant_data, "xan_test_22_331_assembly.fasta")
snp_trees <- ape::read.tree(snp_tree_paths)
snp_alignment<-ape::read.dna(snp_align_paths, format =  "fasta")
#Rename sample names so they don't have prefixes-may be better way
```

## Sample Phylogeny

::: {.panel-tabset}

### SNP phylogeny

```{r div_snp_tree_config, include=FALSE}
#Rename tree tip labels
oldtips<-snp_trees$tip.label
newtips <- gsub(".*_assembly_", "", oldtips)
snp_trees$tip.label<-newtips

# Root tree
#option1
snp_trees_rootref <- root(snp_trees, "REF")
#option2
snp_trees_midpoint<-midpoint(snp_trees)
```

#### ggtree option (starting point)

*May not be most generalizable as one has to specify how color tips-but just another tree option. Very powerful package-but trees are not interactive*

```{r ggtree starting point, eval = ! is.null(snp_trees)}
gg <- ggtree(snp_trees_midpoint) %<+% samp_meta +
  geom_tiplab(size=2.5) +
  geom_tippoint(aes(color=factor(year),fill=factor(year)), size=4.5, stroke=0, alpha=0.75) +
  theme(legend.position="left") +
  guides(color = guide_legend(override.aes = list(size=1))) +
  geom_treescale(fontsize =2.5) 
gg
```

#### Phylocanvas version

```{r div_snp_phylo, fig.height = 7, eval = ! is.null(snp_trees)}
phycanv <- phylocanvas(snp_trees_midpoint, treetype = "rectangular", alignlabels = T, showscalebar = T, width = "100%")
phycanv
```

```{asis div_no_snp_phylo, echo = is.null(snp_trees)}
There is no tree to draw, probably because there were too few samples.
More info will be added later.
```

### ANI tree

:::

## Minimum spanning network

### *Questions to address*

1.  Important discussion point-for running poppr, will user decide on SNP threshold? This differs depending on dataset. Can we use something like poppr *cutoff_predictor* function?

*Martha is actively experimenting. So far looking into Visnetwork, but another option is networkD3?*

```{r poppr_config}
#Specific to output from perl script vcftosnpaln, so need to extract REF from genind (ref remains after using )
snp_aln.gi <- DNAbin2genind(snp_alignment)
snp_aln.gi <- snp_aln.gi[indNames(snp_aln.gi) != "REF"]

#Extract just sample data for relevant sample group(s)? Way to get this from other output and just pull here? 

#Need to rename samples so no longer have prefix (may be better way)
genind_names<-indNames(snp_aln.gi)
cleaned_names <- gsub("22_331_assembly_", "", genind_names)
indNames(snp_aln.gi) <- cleaned_names

```

### MLG table (maybe helpful to include-not sure)

```{r mlg_config}
mat <- match(indNames(snp_aln.gi), samp_meta$sample)
samp_meta <- samp_meta[mat, ]

# Convert to genclone
snp_genclone <- as.genclone(snp_aln.gi)


# Filter genotypes at 5 nucleotides (with the default farthest neighbor algo)
mlg.filter(snp_genclone, distance = bitwise.dist, percent = FALSE) <- 6

idlist<-mlg.id(snp_genclone)

mlglist<-data.frame("MLG","strain")
colnames(mlglist) <- c("V1","V2")
for (name in names(idlist)) {
  newframe<-as.data.frame(cbind(paste0("MLG","_",name),idlist[[name]]))
  mlglist<-rbind(mlglist,newframe)
}

colnames(mlglist)<-c("MLG","strain")
mlglist<-mlglist[mlglist$strain != "strain",]
#make a prettier table
mlglist
```

### Experimenting with less subjective ways to provide SNP cutoff

Please revise as needed. I think we need a better approach to coming up with SNP threshold-as shown in code chunk above. Providing arbitrary cutoff for all datasets will sometimes not be meaningful and even incorrect.

```{r mlg_config_test}
#Experimenting with less subjective approach to identifying good threshold for considering if two samples have the same genotype

snpdist_stats<-filter_stats(snp_genclone)
print(farthest_thresh <- cutoff_predictor(snpdist_stats$farthest$THRESHOLDS))
mlg.filter(snp_genclone, distance = bitwise.dist) <- farthest_thresh
idlist2<-mlg.id(snp_genclone)

mlglist2<-data.frame("MLG","strain")
colnames(mlglist2) <- c("V1","V2")
for (name in names(idlist2)) {
  newframe<-as.data.frame(cbind(paste0("MLG","_",name),idlist2[[name]]))
  mlglist2<-rbind(mlglist2,newframe)
}

colnames(mlglist2)<-c("MLG","strain")
mlglist2<-mlglist2[mlglist2$strain != "strain",]
#make a prettier table
mlglist2
```

### Poppr MSN

```{r poppr msn, fig.height = 10}
# Create a minimum spanning network with filtered data
#Still have issues with metadata-reference seq has none-need way to include? 

#NOTE-cannot have NAs in metadata-for temp fix, changed to NA-may need better solution
samp_meta[is.na(samp_meta)] <- "unknown"

myColors <- rainbow(length(unique(samp_meta$nusery))) 
names(myColors) <- levels(samp_meta$nusery)
#myColors["Other"] <- "#808080"


setPop(snp_genclone) <- ~nusery


# Setting the strata and pop properties
strata(snp_genclone) <- samp_meta[, c(1:18)]
setPop(snp_genclone) <- ~nusery



ms.loc <- poppr.msn(snp_genclone,
                    distmat = bitwise.dist(snp_genclone, percent = FALSE),
                    include.ties = TRUE,
                    showplot = FALSE) # show nothing

#ms.loc$graph[]
#ms.loc
#str(ms.loc)
the_edges <-E(ms.loc$graph)$weight
edges<-as.list(the_edges)

# Plot a pretty plot
set.seed(8)
plot_poppr_msn(
  snp_genclone ,
  poppr_msn = ms.loc,
  palette = myColors,
  mlg = FALSE,
  quantiles = FALSE,
  wscale = FALSE,
  inds="None",
  layfun = layout_with_lgl,
  edge.label = the_edges,
  edge.label.font = 2,
  edge.label.cex = 1,
  edge.lable.family = "Helvetica",
  edge.label.color = "darkslateblue"
  
)
```

### Visnetwork minimum spanning network

*Just started, but needs some work to make a comparable MSN to the one above-including legends. Hard to color nodes like in poppr as pie chart. Need to remove sample names from nodes*

```{r visnetwork_setup}
node_data <- data.frame(
  id = V(ms.loc$graph)$name,
  label = V(ms.loc$graph)$name,
  group = V(ms.loc$graph)$color,
  size = V(ms.loc$graph)$size
)
node_data$value <- node_data$size.Freq

node_data$color <- ms.loc$colors[node_data$group]
node_groups <- lapply(names(ms.loc$colors), function(group_name) {
  list(color = list(background = ms.loc$colors[group_name], border = 'black'))
})
names(node_groups) <- names(ms.loc$colors)
edges_data <- get.data.frame(ms.loc$graph, what="edges")
edges_data$title <- paste("Distance:", edges_data$weight)
edges_data$arrows <- NA

visNetwork(node_data, edges_data) %>%
  visGroups(groupname = node_groups) %>%
  visNodes(shape = "dot", color = node_data$color) %>%
  visInteraction(dragNodes = TRUE, dragView = TRUE, hideEdgesOnDrag = FALSE) %>% 
  #visEdges(arrows = "to") %>%
  visPhysics(stabilization = FALSE) %>%
  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE)
```
```{r visnetwork_setup2}
#visNetwork(node_data, edges_data) %>%
#  visGroups(groupname = node_groups) %>%
#  visNodes(shape = "dot", color = node_data$color) %>%
#  visInteraction(dragNodes = TRUE, dragView = TRUE, hideEdgesOnDrag = FALSE) #%>% 
#  #visEdges(arrows = "to") %>%
#  visPhysics(stabilization = FALSE) %>%
#  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE)
```


### Network D3 experiment









# Quality control


* A quick indicator of status of each step. 

## Input data quality

* multiqc link

## Downloaded references

* quast
* table with rows for each sample with info on references chosen
   - sample id
   - reference id
   - ANI between sample and reference
* table with one row per reference (taxon id, GSA id, classification, link to ncbi)
* sourmash output (tree?)

## Assembly and annotation

* depth of coverage
* quast link
* BUSCO gene content?
* bakta output?       

## Variant calling?

* vcfr for plots
* iqtree model selection, number of informative sites, indels

## Core genome phylogeny

* core gene info (how many genes, length, paralogs)
* outlier samples causing few genes to be chosen
* iqtree model selection, number of informative sites, indels











# About

The **`pathogen surveillance` pipeline** was developed by:

  - Zach Foster, Martha Sudermann, Camilo Parada-Rojas, Fernanda Iruegas-Bocardo, [Jeff Chang](http://changlab.cgrb.oregonstate.edu/) and [Nik Grunwald](http://grunwaldlab.cgrb.oregonstate.edu/).
  - Contributors include [Alex Weisberg](https://alexandra-weisberg.com/), ...
  
> To contribute or report bug please see our [github repository]( https://github.com/nf-core/pathogensurveillance). 
  
Please cite this pipeline in publications as follows: ...






# References

## Methods

The `pathogen surveillance` pipeline used the following tools that should be referenced as appropriate:

  - A sample is first identified to genus using sendsketch and further identified to species using sourmash [@brown2016sourmash].
  - The `nextflow` data-driven computational pipeline enables deployment of complex parallel and reactive workflows [@di2017nextflow].


## Analysis Software

```{r}
DT::datatable(version_data)
```

## Report Software

```{r, include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

```{r}
sessionInfo()
```



## Bibliography

::: {#refs}
:::
